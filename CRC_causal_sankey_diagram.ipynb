{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.io as sio\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import os as os\n",
    "import sys as sys\n",
    "sys.path.append('/home/qiuaodon/Desktop/PanCancer_scRNA_analysis/utils/')\n",
    "from scRNA_utils import *\n",
    "import operator as op\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/qiuaodon/Desktop/project_data_new/populationWide_bootstrap_kernel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Step 1: Load data\n",
    "\n",
    "# Step 2: Group the cell types\n",
    "def group_cell_types(cell, position):\n",
    "    if cell.startswith('B'):\n",
    "        return 'B_from' if position == 'from' else 'B_to'\n",
    "    elif cell.startswith('Mye'):\n",
    "        return 'Mye_from' if position == 'from' else 'Mye_to'\n",
    "    elif cell.startswith('Stromal'):\n",
    "        return 'Stromal_from' if position == 'from' else 'Stromal_to'\n",
    "    elif cell.startswith('Epi'):\n",
    "        return 'Epi_from' if position == 'from' else 'Epi_to'\n",
    "    elif cell.startswith('TNK'):\n",
    "        return 'TNK_from' if position == 'from' else 'TNK_to'\n",
    "    return cell\n",
    "\n",
    "data['from_grouped'] = data['from'].apply(lambda x: group_cell_types(x, 'from'))\n",
    "data['to_grouped'] = data['to'].apply(lambda x: group_cell_types(x, 'to'))\n",
    "\n",
    "# Step 3: Summarize the data by counting unique pairs\n",
    "grouped_data = data.groupby(['from_grouped', 'to_grouped']).size().reset_index(name='pair_count')\n",
    "\n",
    "# Step 4: Prepare the nodes and their order\n",
    "unique_nodes = ['B_from', 'B_to', 'Mye_from', 'Mye_to', \n",
    "                'Stromal_from', 'Stromal_to', 'Epi_from', 'Epi_to', \n",
    "                'TNK_from', 'TNK_to']\n",
    "node_indices = {node: i for i, node in enumerate(unique_nodes)}\n",
    "\n",
    "grouped_data['from_idx'] = grouped_data['from_grouped'].map(node_indices)\n",
    "grouped_data['to_idx'] = grouped_data['to_grouped'].map(node_indices)\n",
    "\n",
    "# Step 5: Define a color palette for the nodes with transparency\n",
    "node_colors = ['rgba(255, 153, 153, 0.5)', 'rgba(255, 153, 153, 0.5)', \n",
    "               'rgba(102, 178, 255, 0.5)', 'rgba(102, 178, 255, 0.5)', \n",
    "               'rgba(153, 255, 153, 0.5)', 'rgba(153, 255, 153, 0.5)', \n",
    "               'rgba(255, 204, 153, 0.5)', 'rgba(255, 204, 153, 0.5)',\n",
    "               'rgba(255, 153, 204, 0.5)', 'rgba(255, 153, 204, 0.5)']\n",
    "\n",
    "# Assign colors to each link based on the source (from) node with transparency\n",
    "link_colors = [node_colors[grouped_data['from_idx'][i]] for i in range(len(grouped_data))]\n",
    "\n",
    "# Step 6: Create the Sankey diagram with transparency\n",
    "fig = go.Figure(go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=unique_nodes,\n",
    "        color=node_colors  # Transparent colors for nodes\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=grouped_data['from_idx'],\n",
    "        target=grouped_data['to_idx'],\n",
    "        value=grouped_data['pair_count'],  # Use pair count instead of frequency\n",
    "        color=link_colors,  # Transparent colors for the edges matching the source (from) node\n",
    "        line=dict(width=0.5)  # Narrower edges\n",
    "    )\n",
    "))\n",
    "\n",
    "# Step 7: Customize the layout to make the figure narrower\n",
    "fig.update_layout(\n",
    "    title_text=\"Cell Type Transitions\",\n",
    "    font_size=10,\n",
    "    width=600,  # Adjust this to make the figure narrower (default is 1000)\n",
    "    height=600  # Adjust the height if necessary\n",
    ")\n",
    "\n",
    "# Step 8: Display the diagram\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "\n",
    "# Step 2: Group the cell types\n",
    "def group_cell_types(cell, position):\n",
    "    if cell.startswith('B'):\n",
    "        return 'B_from' if position == 'from' else 'B_to'\n",
    "    elif cell.startswith('Mye'):\n",
    "        return 'Mye_from' if position == 'from' else 'Mye_to'\n",
    "    elif cell.startswith('Stromal'):\n",
    "        return 'Stromal_from' if position == 'from' else 'Stromal_to'\n",
    "    elif cell.startswith('Epi'):\n",
    "        return 'Epi_from' if position == 'from' else 'Epi_to'\n",
    "    elif cell.startswith('TNK'):\n",
    "        return 'TNK_from' if position == 'from' else 'TNK_to'\n",
    "    return cell\n",
    "\n",
    "data['from_grouped'] = data['from'].apply(lambda x: group_cell_types(x, 'from'))\n",
    "data['to_grouped'] = data['to'].apply(lambda x: group_cell_types(x, 'to'))\n",
    "\n",
    "# Step 3: Summarize the data by counting unique pairs\n",
    "grouped_data = data.groupby(['from_grouped', 'to_grouped']).size().reset_index(name='pair_count')\n",
    "\n",
    "# Step 4: Filter out self-transitions and corresponding transitions (e.g., B_from -> B_to)\n",
    "grouped_data = grouped_data[\n",
    "    (grouped_data['from_grouped'] != grouped_data['to_grouped']) & \n",
    "    ~(\n",
    "        (grouped_data['from_grouped'].str.contains('_from')) & \n",
    "        (grouped_data['to_grouped'].str.contains('_to')) &\n",
    "        (grouped_data['from_grouped'].str.split('_').str[0] == grouped_data['to_grouped'].str.split('_').str[0])\n",
    "    )\n",
    "]\n",
    "\n",
    "# Step 5: Prepare the nodes and their order\n",
    "unique_nodes = ['B_from', 'B_to', \n",
    "                'Mye_from', 'Mye_to', \n",
    "                'Stromal_from', 'Stromal_to', \n",
    "                'Epi_from', 'Epi_to', \n",
    "                'TNK_from', 'TNK_to']\n",
    "\n",
    "node_indices = {node: i for i, node in enumerate(unique_nodes)}\n",
    "\n",
    "grouped_data['from_idx'] = grouped_data['from_grouped'].map(node_indices)\n",
    "grouped_data['to_idx'] = grouped_data['to_grouped'].map(node_indices)\n",
    "\n",
    "# Step 6: Define a color palette for the nodes with transparency\n",
    "node_colors = ['rgba(255, 153, 153, 0.5)', 'rgba(255, 153, 153, 0.5)', \n",
    "               'rgba(102, 178, 255, 0.5)', 'rgba(102, 178, 255, 0.5)', \n",
    "               'rgba(153, 255, 153, 0.5)', 'rgba(153, 255, 153, 0.5)', \n",
    "               'rgba(255, 204, 153, 0.5)', 'rgba(255, 204, 153, 0.5)',\n",
    "               'rgba(255, 153, 204, 0.5)', 'rgba(255, 153, 204, 0.5)']\n",
    "\n",
    "# Assign colors to each link based on the source (from) node with transparency\n",
    "link_colors = [node_colors[int(grouped_data.iloc[i]['from_idx'])] for i in range(len(grouped_data))]\n",
    "\n",
    "# Step 7: Create the Sankey diagram with transparency\n",
    "fig = go.Figure(go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=unique_nodes,\n",
    "        color=node_colors  # Transparent colors for nodes\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=grouped_data['from_idx'],\n",
    "        target=grouped_data['to_idx'],\n",
    "        value=grouped_data['pair_count'],  # Use pair count instead of frequency\n",
    "        color=link_colors,  # Transparent colors for the edges matching the source (from) node\n",
    "        line=dict(width=0.5)  # Narrower edges\n",
    "    )\n",
    "))\n",
    "\n",
    "# Step 8: Customize the layout to make the figure narrower\n",
    "fig.update_layout(\n",
    "    title_text=\"Cross Cell Type Transitions\",\n",
    "    font_size=10,\n",
    "    width=600,  # Adjust this to make the figure narrower (default is 1000)\n",
    "    height=600  # Adjust the height if necessary\n",
    ")\n",
    "\n",
    "# Step 9: Display the diagram\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/qiuaodon/Desktop/project_data_new/populationWide_bootstrap_quantile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Step 1: Load data\n",
    "\n",
    "# Step 2: Group the cell types\n",
    "def group_cell_types(cell, position):\n",
    "    if cell.startswith('B'):\n",
    "        return 'B_from' if position == 'from' else 'B_to'\n",
    "    elif cell.startswith('Mye'):\n",
    "        return 'Mye_from' if position == 'from' else 'Mye_to'\n",
    "    elif cell.startswith('Stromal'):\n",
    "        return 'Stromal_from' if position == 'from' else 'Stromal_to'\n",
    "    elif cell.startswith('Epi'):\n",
    "        return 'Epi_from' if position == 'from' else 'Epi_to'\n",
    "    elif cell.startswith('TNK'):\n",
    "        return 'TNK_from' if position == 'from' else 'TNK_to'\n",
    "    return cell\n",
    "\n",
    "data['from_grouped'] = data['from'].apply(lambda x: group_cell_types(x, 'from'))\n",
    "data['to_grouped'] = data['to'].apply(lambda x: group_cell_types(x, 'to'))\n",
    "\n",
    "# Step 3: Summarize the data by counting unique pairs\n",
    "grouped_data = data.groupby(['from_grouped', 'to_grouped']).size().reset_index(name='pair_count')\n",
    "\n",
    "# Step 4: Prepare the nodes and their order\n",
    "unique_nodes = ['B_from', 'B_to', 'Mye_from', 'Mye_to', \n",
    "                'Stromal_from', 'Stromal_to', 'Epi_from', 'Epi_to', \n",
    "                'TNK_from', 'TNK_to']\n",
    "node_indices = {node: i for i, node in enumerate(unique_nodes)}\n",
    "\n",
    "grouped_data['from_idx'] = grouped_data['from_grouped'].map(node_indices)\n",
    "grouped_data['to_idx'] = grouped_data['to_grouped'].map(node_indices)\n",
    "\n",
    "# Step 5: Define a color palette for the nodes with transparency\n",
    "node_colors = ['rgba(255, 153, 153, 0.5)', 'rgba(255, 153, 153, 0.5)', \n",
    "               'rgba(102, 178, 255, 0.5)', 'rgba(102, 178, 255, 0.5)', \n",
    "               'rgba(153, 255, 153, 0.5)', 'rgba(153, 255, 153, 0.5)', \n",
    "               'rgba(255, 204, 153, 0.5)', 'rgba(255, 204, 153, 0.5)',\n",
    "               'rgba(255, 153, 204, 0.5)', 'rgba(255, 153, 204, 0.5)']\n",
    "\n",
    "# Assign colors to each link based on the source (from) node with transparency\n",
    "link_colors = [node_colors[grouped_data['from_idx'][i]] for i in range(len(grouped_data))]\n",
    "\n",
    "# Step 6: Create the Sankey diagram with transparency\n",
    "fig = go.Figure(go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=unique_nodes,\n",
    "        color=node_colors  # Transparent colors for nodes\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=grouped_data['from_idx'],\n",
    "        target=grouped_data['to_idx'],\n",
    "        value=grouped_data['pair_count'],  # Use pair count instead of frequency\n",
    "        color=link_colors,  # Transparent colors for the edges matching the source (from) node\n",
    "        line=dict(width=0.5)  # Narrower edges\n",
    "    )\n",
    "))\n",
    "\n",
    "# Step 7: Customize the layout to make the figure narrower\n",
    "fig.update_layout(\n",
    "    title_text=\"Cell Type Transitions\",\n",
    "    font_size=10,\n",
    "    width=600,  # Adjust this to make the figure narrower (default is 1000)\n",
    "    height=600  # Adjust the height if necessary\n",
    ")\n",
    "\n",
    "# Step 8: Display the diagram\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "\n",
    "# Step 2: Group the cell types\n",
    "def group_cell_types(cell, position):\n",
    "    if cell.startswith('B'):\n",
    "        return 'B_from' if position == 'from' else 'B_to'\n",
    "    elif cell.startswith('Mye'):\n",
    "        return 'Mye_from' if position == 'from' else 'Mye_to'\n",
    "    elif cell.startswith('Stromal'):\n",
    "        return 'Stromal_from' if position == 'from' else 'Stromal_to'\n",
    "    elif cell.startswith('Epi'):\n",
    "        return 'Epi_from' if position == 'from' else 'Epi_to'\n",
    "    elif cell.startswith('TNK'):\n",
    "        return 'TNK_from' if position == 'from' else 'TNK_to'\n",
    "    return cell\n",
    "\n",
    "data['from_grouped'] = data['from'].apply(lambda x: group_cell_types(x, 'from'))\n",
    "data['to_grouped'] = data['to'].apply(lambda x: group_cell_types(x, 'to'))\n",
    "\n",
    "# Step 3: Summarize the data by counting unique pairs\n",
    "grouped_data = data.groupby(['from_grouped', 'to_grouped']).size().reset_index(name='pair_count')\n",
    "\n",
    "# Step 4: Filter out self-transitions and corresponding transitions (e.g., B_from -> B_to)\n",
    "grouped_data = grouped_data[\n",
    "    (grouped_data['from_grouped'] != grouped_data['to_grouped']) & \n",
    "    ~(\n",
    "        (grouped_data['from_grouped'].str.contains('_from')) & \n",
    "        (grouped_data['to_grouped'].str.contains('_to')) &\n",
    "        (grouped_data['from_grouped'].str.split('_').str[0] == grouped_data['to_grouped'].str.split('_').str[0])\n",
    "    )\n",
    "]\n",
    "\n",
    "# Step 5: Prepare the nodes and their order\n",
    "unique_nodes = ['B_from', 'B_to', \n",
    "                'Mye_from', 'Mye_to', \n",
    "                'Stromal_from', 'Stromal_to', \n",
    "                'Epi_from', 'Epi_to', \n",
    "                'TNK_from', 'TNK_to']\n",
    "\n",
    "node_indices = {node: i for i, node in enumerate(unique_nodes)}\n",
    "\n",
    "grouped_data['from_idx'] = grouped_data['from_grouped'].map(node_indices)\n",
    "grouped_data['to_idx'] = grouped_data['to_grouped'].map(node_indices)\n",
    "\n",
    "# Step 6: Define a color palette for the nodes with transparency\n",
    "node_colors = ['rgba(255, 153, 153, 0.5)', 'rgba(255, 153, 153, 0.5)', \n",
    "               'rgba(102, 178, 255, 0.5)', 'rgba(102, 178, 255, 0.5)', \n",
    "               'rgba(153, 255, 153, 0.5)', 'rgba(153, 255, 153, 0.5)', \n",
    "               'rgba(255, 204, 153, 0.5)', 'rgba(255, 204, 153, 0.5)',\n",
    "               'rgba(255, 153, 204, 0.5)', 'rgba(255, 153, 204, 0.5)']\n",
    "\n",
    "# Assign colors to each link based on the source (from) node with transparency\n",
    "link_colors = [node_colors[int(grouped_data.iloc[i]['from_idx'])] for i in range(len(grouped_data))]\n",
    "\n",
    "# Step 7: Create the Sankey diagram with transparency\n",
    "fig = go.Figure(go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=unique_nodes,\n",
    "        color=node_colors  # Transparent colors for nodes\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=grouped_data['from_idx'],\n",
    "        target=grouped_data['to_idx'],\n",
    "        value=grouped_data['pair_count'],  # Use pair count instead of frequency\n",
    "        color=link_colors,  # Transparent colors for the edges matching the source (from) node\n",
    "        line=dict(width=0.5)  # Narrower edges\n",
    "    )\n",
    "))\n",
    "\n",
    "# Step 8: Customize the layout to make the figure narrower\n",
    "fig.update_layout(\n",
    "    title_text=\"Cross Cell Type Transitions\",\n",
    "    font_size=10,\n",
    "    width=600,  # Adjust this to make the figure narrower (default is 1000)\n",
    "    height=600  # Adjust the height if necessary\n",
    ")\n",
    "\n",
    "# Step 9: Display the diagram\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quantile = pd.read_csv('/home/qiuaodon/Desktop/project_data_new/populationWide_bootstrap_quantile.csv')\n",
    "data_kernel = pd.read_csv('/home/qiuaodon/Desktop/project_data_new/populationWide_bootstrap_kernel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for edge names\n",
    "data_quantile['edge'] = data_quantile['from'] + ' -> ' + data_quantile['to']\n",
    "data_kernel['edge'] = data_kernel['from'] + ' -> ' + data_kernel['to']\n",
    "data_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the venn diagram of the two datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# create a venn diagram\n",
    "plt.figure(figsize=(6, 6))\n",
    "venn2([set(data_quantile['edge']), set(data_kernel['edge'])], set_labels=('Quantile', 'Kernel'))\n",
    "plt.title('Quantile vs Kernel')    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the overlappeing edges\n",
    "quantile_edges = set(data_quantile['edge'])\n",
    "kernel_edges = set(data_kernel['edge'])\n",
    "common_edges = quantile_edges.intersection(kernel_edges)\n",
    "common_edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overlap with the LR_CIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the edge names 'B' -> 'PlasmaB', 'mye' -> 'Myeloid', 'stromal' -> 'Stroma'\n",
    "def change_edge_name(edge):\n",
    "    edge = edge.replace('B', 'PlasmaB')\n",
    "    edge = edge.replace('Mye', 'Myeloid')\n",
    "    edge = edge.replace('Stromal', 'Stroma')\n",
    "    return edge\n",
    "\n",
    "data_quantile['edge'] = data_quantile['edge'].apply(lambda x: change_edge_name(x))\n",
    "data_kernel['edge'] = data_kernel['edge'].apply(lambda x: change_edge_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR = pd.read_csv('/home/qiuaodon/Desktop/project_data_new/LR_passed_search_permutation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR['edge'] = data_LR['from_GEM(X)'] + ' -> ' + data_LR['to_GEM(Y)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the edges that are in the data_quantile or data_kernel\n",
    "data_LR_kernel = data_LR[data_LR['edge'].isin(data_kernel['edge'])]\n",
    "data_LR_quantile = data_LR[data_LR['edge'].isin(data_quantile['edge'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "data_LR_kernel.to_csv('/home/qiuaodon/Desktop/project_data_new/LR_passed_search_permutation_kernel.csv', index=False)\n",
    "data_LR_quantile.to_csv('/home/qiuaodon/Desktop/project_data_new/LR_passed_search_permutation_quantile.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
